user  nginx;
worker_processes  auto;
worker_rlimit_nofile 50000; # to increase the maximum number of open files for worker process
worker_cpu_affinity  auto; # Binds worker processes to the sets of CPUs(CPU Affinity)

error_log  /var/log/nginx/error.log notice;
pid        /var/run/nginx.pid;


events {
    worker_connections 10240; #Sets the maximum number of simultaneous connections that can be opened by a worker process default is 1024
    accept_mutex off; #if turned off, all worker processes will be notified about new connections rather than by turn (default off)
    multi_accept on; #if it is enabled a worker process will accept all new connections at a time (default is off)
    use epoll; #Specifies which Linux kernel method to use for performing event based I/O operations, NGINX by default selects efficient method based on kernel version, epoll method is efficient for Linux kernel 2.6 and above 
}


http {
    aio on; #Enables threadpools, this creates set of threads per worker process to efficiently handle blocking syscalls.
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    # Content Caching
    proxy_cache_path /tmp/nginx-cache keys_zone=nginx-cache:10m levels=1:2 inactive=120s max_size=100m;

    # Purge cache
    map $request_method $purge_method {
        PURGE 1;
        default 0;
    }

    # HTTPS Server Optimization
    # Source: https://docs.nginx.com/nginx/admin-guide/security-controls/terminating-ssl-http/#https-server-optimization
    ssl_session_cache   shared:SSL:10m;
    ssl_session_timeout 10m;

    # Connection & rate request limit
    # This connection & request limit was based on IP addres as binary_remote_addr variable used. 
    # For reference on using other variable refer to this link: https://nginx.org/en/docs/http/ngx_http_core_module.html#variables
    #limit_conn_zone $binary_remote_addr zone=conn_limit:5m;
    #limit_req_zone $binary_remote_addr zone=rate_limit:5m rate=50r/s sync;

    # Logging
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request_method $scheme://$host$request_uri $server_protocol" "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    #access_log  /var/log/nginx/access.log  main;
    access_log off; # we don't want disk IO to slow down nginx
    sendfile on; # reference file descriptor instead of copying into memory

   #tcp_nopush     on;

    keepalive_timeout  65;

    #gzip  on;

    # Hiding the server token
    server_tokens "";

    # Add DNS service discovery
    resolver 192.168.200.34 valid=20s;

    include /etc/nginx/conf.d/*.conf;
    include /etc/nginx/api-conf.d/*.conf;
}


# If several NGINX Plus instances are organized in a cluster, 
# they can share some state data between them, including:
#
#     - sticky learn session persistence
#     - requests limiting
#     - key-value storage
#
# Reference: https://docs.nginx.com/nginx/admin-guide/high-availability/zone_sync/

#stream {

    #  resolver 10.0.0.53 valid=20s;

    # server {
        # listen 177.100.10.4:9000;
        # listen 177.100.10.5:9000;

        #  ssl_certificate_key /etc/ssl/nginx-1.example.com.key.pem;
        #  ssl_certificate     /etc/ssl/nginx-1.example.com.server_cert.pem;

        # zone_sync;
        # zone_sync_server 177.100.10.4:9000;
        # zone_sync_server 177.100.10.5:9000;

        #  zone_sync_ssl;
        #  zone_sync_ssl_certificate     localhost.crt;
        #  zone_sync_ssl_certificate_key localhost.key;

        #  zone_sync_ssl_verify              on;
        #  zone_sync_ssl_verify_depth        2;
        #  zone_sync_ssl_trusted_certificate /etc/ssl/ca_chain.crt.pem;
#     }
# }


# TCP/UDP proxy and load balancing block
#
#stream {
    # Example configuration for TCP load balancing

    #upstream stream_backend {
    #    zone tcp_servers 64k;
    #    server backend1.example.com:12345;
    #    server backend2.example.com:12345;
    #}

    #server {
    #    listen 12345;
    #    status_zone tcp_server;
    #    proxy_pass stream_backend;
    #}
#}

